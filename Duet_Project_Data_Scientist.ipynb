{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-crisis",
   "metadata": {},
   "source": [
    "# Part 1: Join the Duet Server the Data Owner connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reserved-chain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-beast",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 0 : Now STOP and run the Data Owner notebook until Checkpoint 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-suffering",
   "metadata": {},
   "source": [
    "# Part 2: Search for Available Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virtual-small",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 5cb957a9c62342139256f9aeb73b39f0&gt;</td>\n",
       "      <td>[Loan-data]</td>\n",
       "      <td>This is a train dataset for Credit Default cla...</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: ce5bd4bc2dee4d0aa03d877ce6e3da3e&gt;</td>\n",
       "      <td>[Loan-target]</td>\n",
       "      <td>Labels for Defaulted: No, Yes</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID           Tags  \\\n",
       "0  <UID: 5cb957a9c62342139256f9aeb73b39f0>    [Loan-data]   \n",
       "1  <UID: ce5bd4bc2dee4d0aa03d877ce6e3da3e>  [Loan-target]   \n",
       "\n",
       "                                         Description             object_type  \n",
       "0  This is a train dataset for Credit Default cla...  <class 'torch.Tensor'>  \n",
       "1                      Labels for Defaulted: No, Yes  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data scientist can check the list of searchable data in Data Owner's duet store\n",
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-cutting",
   "metadata": {},
   "source": [
    "Data Scientist wants to use the Bank dataset. (S)He needs a pointer to the data and\n",
    "a pointer to the target for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "statewide-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr = duet.store[0]\n",
    "target_ptr = duet.store[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-interaction",
   "metadata": {},
   "source": [
    "`data_ptr` is a reference to the iris dataset remotely available on data owner's server.\n",
    "`target_ptr` is a reference to the iris dataset LABELS remotely available on data owner's server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x0000019008752760>\n",
      "<syft.proxy.torch.TensorPointer object at 0x0000019008752850>\n"
     ]
    }
   ],
   "source": [
    "print(data_ptr)\n",
    "print(target_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-english",
   "metadata": {},
   "source": [
    "# Part 3: Perform Logistic Regression on Bank dataset\n",
    "Now the data scientist can perform machine learning on the data that is in the Data Owner's duet server, without the owner having to share his/her data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-dominican",
   "metadata": {},
   "source": [
    "### Basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-symphony",
   "metadata": {},
   "source": [
    "First the data scientist needs to know some basic information about the dataset.\n",
    "1. The length of the dataset\n",
    "2. The input dimension\n",
    "3. The output dimension\n",
    "\n",
    "These information have to be explicitly shared by the Data Owner. Let's try to find them in the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crucial-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a train dataset for Credit Default classification.\n",
      "\n",
      "Labels for Defaulted: No, Yes\n"
     ]
    }
   ],
   "source": [
    "print(duet.store.pandas[\"Description\"][0])\n",
    "print()\n",
    "print(duet.store.pandas[\"Description\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-destruction",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disabled-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from random import seed\n",
    "from csv import reader \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cutting-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 71\n",
    "out_dim = 2\n",
    "n_samples = 8360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-belgium",
   "metadata": {},
   "source": [
    "First, let's create our model for `Logistic Regression`. If you are already familiar with PyTorch, you will notice that the model is built almost the exact same way as you do in PyTorch. The main difference is that here we inherit from `sy.Module` instead of `nn.Module`. We also need to pass in a variable called `torch_ref` which we will use internally for any calls that you would normally make to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accurate-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.layer1 = self.torch_ref.nn.Linear(in_dim, 100)\n",
    "        self.layer2 = self.torch_ref.nn.Linear(100, 100)\n",
    "        self.out = self.torch_ref.nn.Linear(100, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer1(x))\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer2(x))\n",
    "        output = self.torch_ref.nn.functional.log_softmax(self.out(x), dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-macro",
   "metadata": {},
   "source": [
    "Now we can create a local model by passing our local copy of torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appreciated-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-surge",
   "metadata": {},
   "source": [
    "Now we will send the local copy of the model to our partner's duet server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spare-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model = local_model.send(duet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-calgary",
   "metadata": {},
   "source": [
    "Let's create an alias for our partnerâ€™s torch called `remote_torch` so we can refer to the local torch as torch and any operation we want to do remotely as `remote_torch`. Remember, the return values from `remote_torch` are Pointers, not the real objects. They mostly act the same when using them with other Pointers but they cannot be mixed with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caroline-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-samba",
   "metadata": {},
   "source": [
    "We will get a pointer to our remote model parameters. Then we will set our optimizer. Here, we will be using `Adam optimizer`. `params` is a pointer to the list of parameters. `optim` is a reference to the Adam optimizer which can be used to optimize the remote model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wooden-strip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: <syft.proxy.syft.lib.python.ListPointer object at 0x0000019008752CD0>\n",
      "optim: <syft.proxy.torch.optim.AdamPointer object at 0x000001900831FA30>\n"
     ]
    }
   ],
   "source": [
    "params = remote_model.parameters()\n",
    "optim = remote_torch.optim.Adam(params=params, lr=0.01)\n",
    "print(\"params:\", params)\n",
    "print(\"optim:\", optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-acoustic",
   "metadata": {},
   "source": [
    "Now we will create our `train` function. It will take few parameters, like the `remote_model`, `torch_ref`, `optim` and `data_ptr` and `target_ptr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monetary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        # nll_loss = negative log-liklihood loss\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr.long())\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\", request_block=True, timeout_secs=5\n",
    "        )\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "responsible-international",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.24264490604400635\n",
      "Epoch 10 loss 0.23889362812042236\n",
      "Epoch 20 loss 0.23545600473880768\n",
      "Epoch 30 loss 0.23228685557842255\n",
      "Epoch 40 loss 0.22932256758213043\n",
      "Epoch 50 loss 0.2379290759563446\n",
      "Epoch 60 loss 0.710316002368927\n",
      "Epoch 70 loss 0.4474920928478241\n",
      "Epoch 80 loss 0.4065604507923126\n",
      "Epoch 90 loss 0.3138148784637451\n",
      "Epoch 100 loss 0.2606933116912842\n",
      "Epoch 110 loss 0.23669233918190002\n",
      "Epoch 120 loss 0.23380990326404572\n",
      "Epoch 130 loss 0.22910615801811218\n",
      "Epoch 140 loss 0.22571298480033875\n",
      "Epoch 150 loss 0.22313348948955536\n",
      "Epoch 160 loss 0.22098924219608307\n",
      "Epoch 170 loss 0.21893109381198883\n",
      "Epoch 180 loss 0.21699558198451996\n",
      "Epoch 190 loss 0.21514131128787994\n",
      "Epoch 200 loss 0.21337071061134338\n",
      "Epoch 210 loss 0.21333768963813782\n",
      "Epoch 220 loss 0.35378319025039673\n",
      "Epoch 230 loss 0.4522413909435272\n",
      "Epoch 240 loss 0.3984851837158203\n",
      "Epoch 250 loss 0.2624441385269165\n",
      "Epoch 260 loss 0.2402951568365097\n",
      "Epoch 270 loss 0.22255383431911469\n",
      "Epoch 280 loss 0.21823063492774963\n",
      "Epoch 290 loss 0.21533681452274323\n"
     ]
    }
   ],
   "source": [
    "iteration = 300\n",
    "losses = train(iteration, remote_model, remote_torch, optim, data_ptr, target_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "generous-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "established-illinois",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'iteration')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(iteration), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-judge",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "healthy-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_model(model):\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"To run test and inference locally\",\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "\n",
    "    return local_model\n",
    "\n",
    "\n",
    "local_model = get_local_model(remote_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-amateur",
   "metadata": {},
   "source": [
    "### Test on local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "generous-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "minimal-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VerificationType</th>\n",
       "      <th>LanguageCode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AppliedAmount</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Interest</th>\n",
       "      <th>LoanDuration</th>\n",
       "      <th>MonthlyPayment</th>\n",
       "      <th>UseOfLoan</th>\n",
       "      <th>...</th>\n",
       "      <th>Rating_F</th>\n",
       "      <th>Rating_HR</th>\n",
       "      <th>Rating_nan</th>\n",
       "      <th>Status_Late</th>\n",
       "      <th>Status_Repaid</th>\n",
       "      <th>Status_nan</th>\n",
       "      <th>Restructured_True</th>\n",
       "      <th>Restructured_nan</th>\n",
       "      <th>diff_days</th>\n",
       "      <th>Defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.292715</td>\n",
       "      <td>0.292715</td>\n",
       "      <td>0.061933</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.056659</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414284</td>\n",
       "      <td>0.414284</td>\n",
       "      <td>0.140012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065239</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192136</td>\n",
       "      <td>0.192136</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.141229</td>\n",
       "      <td>0.141229</td>\n",
       "      <td>0.197744</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.036761</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039415</td>\n",
       "      <td>0.039415</td>\n",
       "      <td>0.053530</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VerificationType  LanguageCode       Age  Gender  AppliedAmount    Amount  \\\n",
       "0               4.0             1  0.442308     1.0       0.292715  0.292715   \n",
       "1               4.0             1  0.576923     1.0       0.414284  0.414284   \n",
       "2               4.0             3  0.442308     1.0       0.192136  0.192136   \n",
       "3               4.0             6  0.519231     2.0       0.141229  0.141229   \n",
       "4               4.0             4  0.346154     0.0       0.039415  0.039415   \n",
       "\n",
       "   Interest  LoanDuration  MonthlyPayment  UseOfLoan  ...  Rating_F  \\\n",
       "0  0.061933      0.282051        0.056659          2  ...         0   \n",
       "1  0.140012      1.000000        0.065239          9  ...         0   \n",
       "2  0.076600      0.487179        0.028883          9  ...         0   \n",
       "3  0.197744      0.487179        0.036761          9  ...         1   \n",
       "4  0.053530      0.487179        0.005704          9  ...         0   \n",
       "\n",
       "   Rating_HR  Rating_nan  Status_Late  Status_Repaid  Status_nan  \\\n",
       "0          0           0            0              1           0   \n",
       "1          0           0            1              0           0   \n",
       "2          0           0            0              1           0   \n",
       "3          0           0            0              1           0   \n",
       "4          0           0            0              0           0   \n",
       "\n",
       "   Restructured_True  Restructured_nan  diff_days  Defaulted  \n",
       "0                  0                 0     1125.0          1  \n",
       "1                  0                 0     3639.0          1  \n",
       "2                  0                 0     1820.0          1  \n",
       "3                  0                 0      125.0          0  \n",
       "4                  0                 0     1819.0          0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_test = pd.read_csv(\"C:/Data Science and Analytics/DSA 5900/Final Deliverable/Test.csv\")\n",
    "project_test.drop(['Unnamed: 0'] , axis = 1, inplace =True)\n",
    "\n",
    "project_test = project_test.dropna()\n",
    "project_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "explicit-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = project_test.loc[:, project_test.columns != \"Defaulted\"]\n",
    "y_test = project_test[\"Defaulted\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "finnish-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(np.array(X_test))\n",
    "y_test = torch.LongTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wicked-waste",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "preds1 = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        sample = X_test[i]\n",
    "        y_hat = local_model(sample.unsqueeze(0))\n",
    "        preds1.append(y_hat)\n",
    "        pred = y_hat.argmax().item()\n",
    "        #print(f\"Prediction: {pred} Ground Truth: {y_test[i]}\")\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "collaborative-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test accuracy 90.7177033492823\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Overall test accuracy\", acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31f6671a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "literary-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below code converts the log_softmax to softmax to estimate probabilities of the +ve and the -ve classes\n",
    "\n",
    "probs = []\n",
    "\n",
    "for i in range(len(preds1)):\n",
    "    probs.append(torch.exp(preds1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "402861ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.6000, 0.4000]]),\n",
       " tensor([[0.5050, 0.4950]]),\n",
       " tensor([[0.9608, 0.0392]]),\n",
       " tensor([[1.0000e+00, 7.6565e-07]]),\n",
       " tensor([[0.9934, 0.0066]]),\n",
       " tensor([[0.6822, 0.3178]]),\n",
       " tensor([[0.9710, 0.0290]]),\n",
       " tensor([[0.1711, 0.8289]]),\n",
       " tensor([[0.9715, 0.0285]]),\n",
       " tensor([[0.9888, 0.0112]]),\n",
       " tensor([[0.8225, 0.1775]]),\n",
       " tensor([[0.9968, 0.0032]]),\n",
       " tensor([[0.9920, 0.0080]]),\n",
       " tensor([[0.0900, 0.9100]]),\n",
       " tensor([[0.1087, 0.8913]]),\n",
       " tensor([[0.9883, 0.0117]]),\n",
       " tensor([[0.9654, 0.0346]]),\n",
       " tensor([[0.9900, 0.0100]]),\n",
       " tensor([[0.9981, 0.0019]]),\n",
       " tensor([[0.9845, 0.0155]]),\n",
       " tensor([[0.1195, 0.8805]]),\n",
       " tensor([[0.0171, 0.9829]]),\n",
       " tensor([[0.8905, 0.1095]]),\n",
       " tensor([[0.9511, 0.0489]]),\n",
       " tensor([[0.9983, 0.0017]]),\n",
       " tensor([[0.1533, 0.8467]]),\n",
       " tensor([[0.9976, 0.0024]]),\n",
       " tensor([[0.8257, 0.1743]]),\n",
       " tensor([[0.0047, 0.9953]]),\n",
       " tensor([[0.4573, 0.5427]]),\n",
       " tensor([[0.3752, 0.6248]]),\n",
       " tensor([[0.9914, 0.0086]]),\n",
       " tensor([[0.4657, 0.5343]]),\n",
       " tensor([[0.0263, 0.9737]]),\n",
       " tensor([[0.3105, 0.6895]]),\n",
       " tensor([[0.1498, 0.8502]]),\n",
       " tensor([[0.9712, 0.0288]]),\n",
       " tensor([[0.9640, 0.0360]]),\n",
       " tensor([[0.9975, 0.0025]]),\n",
       " tensor([[0.9448, 0.0552]]),\n",
       " tensor([[0.5169, 0.4831]]),\n",
       " tensor([[0.9847, 0.0153]]),\n",
       " tensor([[0.0232, 0.9768]]),\n",
       " tensor([[0.9870, 0.0130]]),\n",
       " tensor([[0.9939, 0.0061]]),\n",
       " tensor([[0.9381, 0.0619]]),\n",
       " tensor([[0.0823, 0.9177]]),\n",
       " tensor([[0.9813, 0.0187]]),\n",
       " tensor([[0.9968, 0.0032]]),\n",
       " tensor([[0.9167, 0.0833]]),\n",
       " tensor([[0.2869, 0.7131]]),\n",
       " tensor([[0.0185, 0.9815]]),\n",
       " tensor([[0.0102, 0.9898]]),\n",
       " tensor([[0.9935, 0.0065]]),\n",
       " tensor([[0.8661, 0.1339]]),\n",
       " tensor([[0.7905, 0.2095]]),\n",
       " tensor([[0.1111, 0.8889]]),\n",
       " tensor([[0.7035, 0.2965]]),\n",
       " tensor([[0.0032, 0.9968]]),\n",
       " tensor([[0.8202, 0.1798]]),\n",
       " tensor([[0.8929, 0.1071]]),\n",
       " tensor([[0.9868, 0.0132]]),\n",
       " tensor([[0.7483, 0.2517]]),\n",
       " tensor([[0.0252, 0.9748]]),\n",
       " tensor([[1.0000e+00, 7.3149e-14]]),\n",
       " tensor([[1.0000e+00, 1.1084e-21]]),\n",
       " tensor([[0.0048, 0.9952]]),\n",
       " tensor([[0.0046, 0.9954]]),\n",
       " tensor([[0.0026, 0.9974]]),\n",
       " tensor([[0.9901, 0.0099]]),\n",
       " tensor([[0.9918, 0.0082]]),\n",
       " tensor([[0.9629, 0.0371]]),\n",
       " tensor([[0.5172, 0.4828]]),\n",
       " tensor([[0.9415, 0.0585]]),\n",
       " tensor([[0.0396, 0.9604]]),\n",
       " tensor([[0.9943, 0.0057]]),\n",
       " tensor([[0.9962, 0.0038]]),\n",
       " tensor([[0.8857, 0.1143]]),\n",
       " tensor([[0.0316, 0.9684]]),\n",
       " tensor([[0.9892, 0.0108]]),\n",
       " tensor([[0.0265, 0.9735]]),\n",
       " tensor([[0.9957, 0.0043]]),\n",
       " tensor([[0.8703, 0.1297]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[1.0000e+00, 2.5313e-21]]),\n",
       " tensor([[0.9562, 0.0438]]),\n",
       " tensor([[0.0490, 0.9510]]),\n",
       " tensor([[0.1237, 0.8763]]),\n",
       " tensor([[0.0165, 0.9835]]),\n",
       " tensor([[0.9832, 0.0168]]),\n",
       " tensor([[0.0031, 0.9969]]),\n",
       " tensor([[0.9911, 0.0089]]),\n",
       " tensor([[0.0683, 0.9317]]),\n",
       " tensor([[0.9907, 0.0093]]),\n",
       " tensor([[0.0706, 0.9294]]),\n",
       " tensor([[0.7787, 0.2213]]),\n",
       " tensor([[0.9943, 0.0057]]),\n",
       " tensor([[0.9951, 0.0049]]),\n",
       " tensor([[0.1317, 0.8683]]),\n",
       " tensor([[0.9955, 0.0045]]),\n",
       " tensor([[0.8543, 0.1457]]),\n",
       " tensor([[1.0000e+00, 4.1196e-21]]),\n",
       " tensor([[0.9931, 0.0069]]),\n",
       " tensor([[0.9555, 0.0445]]),\n",
       " tensor([[0.9846, 0.0154]]),\n",
       " tensor([[0.1059, 0.8941]]),\n",
       " tensor([[0.7940, 0.2060]]),\n",
       " tensor([[0.8157, 0.1843]]),\n",
       " tensor([[0.9561, 0.0439]]),\n",
       " tensor([[0.8691, 0.1309]]),\n",
       " tensor([[0.0198, 0.9802]]),\n",
       " tensor([[0.9814, 0.0186]]),\n",
       " tensor([[0.0075, 0.9925]]),\n",
       " tensor([[0.9812, 0.0188]]),\n",
       " tensor([[0.8743, 0.1257]]),\n",
       " tensor([[0.9916, 0.0084]]),\n",
       " tensor([[0.5669, 0.4331]]),\n",
       " tensor([[0.9363, 0.0637]]),\n",
       " tensor([[1.0000e+00, 1.5442e-21]]),\n",
       " tensor([[9.9997e-01, 3.1885e-05]]),\n",
       " tensor([[0.8536, 0.1464]]),\n",
       " tensor([[0.8104, 0.1896]]),\n",
       " tensor([[0.9635, 0.0365]]),\n",
       " tensor([[0.9901, 0.0099]]),\n",
       " tensor([[0.9932, 0.0068]]),\n",
       " tensor([[0.3792, 0.6208]]),\n",
       " tensor([[0.9983, 0.0017]]),\n",
       " tensor([[0.9786, 0.0214]]),\n",
       " tensor([[1.0000e+00, 2.3921e-20]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[0.0199, 0.9801]]),\n",
       " tensor([[0.8021, 0.1979]]),\n",
       " tensor([[0.9969, 0.0031]]),\n",
       " tensor([[0.0755, 0.9245]]),\n",
       " tensor([[0.9416, 0.0584]]),\n",
       " tensor([[0.5754, 0.4246]]),\n",
       " tensor([[0.2324, 0.7676]]),\n",
       " tensor([[0.1178, 0.8822]]),\n",
       " tensor([[0.9911, 0.0089]]),\n",
       " tensor([[0.9886, 0.0114]]),\n",
       " tensor([[0.0352, 0.9648]]),\n",
       " tensor([[0.0332, 0.9668]]),\n",
       " tensor([[0.9680, 0.0320]]),\n",
       " tensor([[0.9878, 0.0122]]),\n",
       " tensor([[0.9936, 0.0064]]),\n",
       " tensor([[0.7438, 0.2562]]),\n",
       " tensor([[0.9723, 0.0277]]),\n",
       " tensor([[0.9902, 0.0098]]),\n",
       " tensor([[0.0320, 0.9680]]),\n",
       " tensor([[0.5965, 0.4035]]),\n",
       " tensor([[0.0116, 0.9884]]),\n",
       " tensor([[0.9878, 0.0122]]),\n",
       " tensor([[0.9548, 0.0452]]),\n",
       " tensor([[0.8647, 0.1353]]),\n",
       " tensor([[0.7269, 0.2731]]),\n",
       " tensor([[0.0240, 0.9760]]),\n",
       " tensor([[0.1557, 0.8443]]),\n",
       " tensor([[0.4547, 0.5453]]),\n",
       " tensor([[0.1550, 0.8450]]),\n",
       " tensor([[0.1155, 0.8845]]),\n",
       " tensor([[0.9151, 0.0849]]),\n",
       " tensor([[0.1260, 0.8740]]),\n",
       " tensor([[0.9974, 0.0026]]),\n",
       " tensor([[0.9914, 0.0086]]),\n",
       " tensor([[0.9432, 0.0568]]),\n",
       " tensor([[0.9823, 0.0177]]),\n",
       " tensor([[0.0221, 0.9779]]),\n",
       " tensor([[0.8771, 0.1229]]),\n",
       " tensor([[0.8614, 0.1386]]),\n",
       " tensor([[9.9985e-01, 1.4856e-04]]),\n",
       " tensor([[0.9365, 0.0635]]),\n",
       " tensor([[0.0189, 0.9811]]),\n",
       " tensor([[9.9920e-01, 7.9803e-04]]),\n",
       " tensor([[0.9962, 0.0038]]),\n",
       " tensor([[0.9980, 0.0020]]),\n",
       " tensor([[0.9895, 0.0105]]),\n",
       " tensor([[0.9943, 0.0057]]),\n",
       " tensor([[0.0738, 0.9262]]),\n",
       " tensor([[0.9767, 0.0233]]),\n",
       " tensor([[0.9959, 0.0041]]),\n",
       " tensor([[1.0000e+00, 1.0870e-21]]),\n",
       " tensor([[0.1299, 0.8701]]),\n",
       " tensor([[0.9730, 0.0270]]),\n",
       " tensor([[0.7280, 0.2720]]),\n",
       " tensor([[0.9867, 0.0133]]),\n",
       " tensor([[0.0251, 0.9749]]),\n",
       " tensor([[0.0819, 0.9181]]),\n",
       " tensor([[0.9979, 0.0021]]),\n",
       " tensor([[0.8657, 0.1343]]),\n",
       " tensor([[0.9387, 0.0613]]),\n",
       " tensor([[0.9675, 0.0325]]),\n",
       " tensor([[1.0000e+00, 4.7165e-24]]),\n",
       " tensor([[0.7472, 0.2528]]),\n",
       " tensor([[0.8618, 0.1382]]),\n",
       " tensor([[0.0220, 0.9780]]),\n",
       " tensor([[0.4586, 0.5414]]),\n",
       " tensor([[0.8751, 0.1249]]),\n",
       " tensor([[9.9999e-01, 1.0942e-05]]),\n",
       " tensor([[0.2304, 0.7696]]),\n",
       " tensor([[0.9371, 0.0629]]),\n",
       " tensor([[0.9984, 0.0016]]),\n",
       " tensor([[0.9735, 0.0265]]),\n",
       " tensor([[0.9762, 0.0238]]),\n",
       " tensor([[0.0035, 0.9965]]),\n",
       " tensor([[0.9963, 0.0037]]),\n",
       " tensor([[0.9971, 0.0029]]),\n",
       " tensor([[0.9813, 0.0187]]),\n",
       " tensor([[0.9913, 0.0087]]),\n",
       " tensor([[0.9724, 0.0276]]),\n",
       " tensor([[0.8451, 0.1549]]),\n",
       " tensor([[0.9952, 0.0048]]),\n",
       " tensor([[0.7779, 0.2221]]),\n",
       " tensor([[0.1603, 0.8397]]),\n",
       " tensor([[0.0920, 0.9080]]),\n",
       " tensor([[0.9655, 0.0345]]),\n",
       " tensor([[0.9962, 0.0038]]),\n",
       " tensor([[0.9205, 0.0795]]),\n",
       " tensor([[0.9691, 0.0309]]),\n",
       " tensor([[0.6514, 0.3486]]),\n",
       " tensor([[0.0592, 0.9408]]),\n",
       " tensor([[0.9308, 0.0692]]),\n",
       " tensor([[0.9982, 0.0018]]),\n",
       " tensor([[0.0815, 0.9185]]),\n",
       " tensor([[0.0608, 0.9392]]),\n",
       " tensor([[0.9101, 0.0899]]),\n",
       " tensor([[0.2529, 0.7471]]),\n",
       " tensor([[0.9051, 0.0949]]),\n",
       " tensor([[0.7979, 0.2021]]),\n",
       " tensor([[0.9965, 0.0035]]),\n",
       " tensor([[0.9919, 0.0081]]),\n",
       " tensor([[0.4623, 0.5377]]),\n",
       " tensor([[0.8810, 0.1190]]),\n",
       " tensor([[0.0031, 0.9969]]),\n",
       " tensor([[0.9684, 0.0316]]),\n",
       " tensor([[0.9907, 0.0093]]),\n",
       " tensor([[0.1367, 0.8633]]),\n",
       " tensor([[0.1215, 0.8785]]),\n",
       " tensor([[0.9956, 0.0044]]),\n",
       " tensor([[0.8642, 0.1358]]),\n",
       " tensor([[0.5250, 0.4750]]),\n",
       " tensor([[0.0032, 0.9968]]),\n",
       " tensor([[0.7969, 0.2031]]),\n",
       " tensor([[0.1260, 0.8740]]),\n",
       " tensor([[0.9803, 0.0197]]),\n",
       " tensor([[0.0028, 0.9972]]),\n",
       " tensor([[0.6339, 0.3661]]),\n",
       " tensor([[0.0816, 0.9184]]),\n",
       " tensor([[0.0745, 0.9255]]),\n",
       " tensor([[0.6778, 0.3222]]),\n",
       " tensor([[1.0000e+00, 7.1515e-08]]),\n",
       " tensor([[0.4699, 0.5301]]),\n",
       " tensor([[0.8523, 0.1477]]),\n",
       " tensor([[0.0128, 0.9872]]),\n",
       " tensor([[0.0308, 0.9692]]),\n",
       " tensor([[0.9942, 0.0058]]),\n",
       " tensor([[0.8083, 0.1917]]),\n",
       " tensor([[0.9838, 0.0162]]),\n",
       " tensor([[0.2228, 0.7772]]),\n",
       " tensor([[0.9951, 0.0049]]),\n",
       " tensor([[0.9978, 0.0022]]),\n",
       " tensor([[0.9974, 0.0026]]),\n",
       " tensor([[0.9945, 0.0055]]),\n",
       " tensor([[0.7550, 0.2450]]),\n",
       " tensor([[0.2274, 0.7726]]),\n",
       " tensor([[0.9702, 0.0298]]),\n",
       " tensor([[0.9332, 0.0668]]),\n",
       " tensor([[0.9939, 0.0061]]),\n",
       " tensor([[0.3061, 0.6939]]),\n",
       " tensor([[0.8808, 0.1192]]),\n",
       " tensor([[0.9682, 0.0318]]),\n",
       " tensor([[0.9977, 0.0023]]),\n",
       " tensor([[0.0228, 0.9772]]),\n",
       " tensor([[0.9556, 0.0444]]),\n",
       " tensor([[0.9102, 0.0898]]),\n",
       " tensor([[0.9732, 0.0268]]),\n",
       " tensor([[0.9745, 0.0255]]),\n",
       " tensor([[0.9933, 0.0067]]),\n",
       " tensor([[0.9960, 0.0040]]),\n",
       " tensor([[1.0000e+00, 8.6531e-11]]),\n",
       " tensor([[0.0389, 0.9611]]),\n",
       " tensor([[0.8810, 0.1190]]),\n",
       " tensor([[0.9194, 0.0806]]),\n",
       " tensor([[0.5068, 0.4932]]),\n",
       " tensor([[0.9888, 0.0112]]),\n",
       " tensor([[0.0619, 0.9381]]),\n",
       " tensor([[0.9901, 0.0099]]),\n",
       " tensor([[0.0281, 0.9719]]),\n",
       " tensor([[0.8775, 0.1225]]),\n",
       " tensor([[0.9970, 0.0030]]),\n",
       " tensor([[0.9944, 0.0056]]),\n",
       " tensor([[0.8320, 0.1680]]),\n",
       " tensor([[0.9249, 0.0751]]),\n",
       " tensor([[0.0862, 0.9138]]),\n",
       " tensor([[0.0240, 0.9760]]),\n",
       " tensor([[0.0833, 0.9167]]),\n",
       " tensor([[0.9931, 0.0069]]),\n",
       " tensor([[0.9874, 0.0126]]),\n",
       " tensor([[0.9901, 0.0099]]),\n",
       " tensor([[1.0000e+00, 4.8958e-06]]),\n",
       " tensor([[0.8102, 0.1898]]),\n",
       " tensor([[0.6412, 0.3588]]),\n",
       " tensor([[0.0310, 0.9690]]),\n",
       " tensor([[0.2782, 0.7218]]),\n",
       " tensor([[0.6837, 0.3163]]),\n",
       " tensor([[0.0269, 0.9731]]),\n",
       " tensor([[0.9607, 0.0393]]),\n",
       " tensor([[0.9750, 0.0250]]),\n",
       " tensor([[9.9928e-01, 7.2116e-04]]),\n",
       " tensor([[0.9336, 0.0664]]),\n",
       " tensor([[0.1238, 0.8762]]),\n",
       " tensor([[0.8310, 0.1690]]),\n",
       " tensor([[0.7427, 0.2573]]),\n",
       " tensor([[0.9419, 0.0581]]),\n",
       " tensor([[0.9765, 0.0235]]),\n",
       " tensor([[0.9699, 0.0301]]),\n",
       " tensor([[0.9963, 0.0037]]),\n",
       " tensor([[0.9875, 0.0125]]),\n",
       " tensor([[0.0039, 0.9961]]),\n",
       " tensor([[0.0270, 0.9730]]),\n",
       " tensor([[0.7907, 0.2093]]),\n",
       " tensor([[0.9980, 0.0020]]),\n",
       " tensor([[0.0183, 0.9817]]),\n",
       " tensor([[0.9981, 0.0019]]),\n",
       " tensor([[0.3286, 0.6714]]),\n",
       " tensor([[0.9817, 0.0183]]),\n",
       " tensor([[0.1461, 0.8539]]),\n",
       " tensor([[0.9346, 0.0654]]),\n",
       " tensor([[0.7673, 0.2327]]),\n",
       " tensor([[0.8237, 0.1763]]),\n",
       " tensor([[0.0205, 0.9795]]),\n",
       " tensor([[0.9898, 0.0102]]),\n",
       " tensor([[0.2265, 0.7735]]),\n",
       " tensor([[0.0071, 0.9929]]),\n",
       " tensor([[1.0000e+00, 7.3671e-14]]),\n",
       " tensor([[0.9914, 0.0086]]),\n",
       " tensor([[0.9951, 0.0049]]),\n",
       " tensor([[0.9959, 0.0041]]),\n",
       " tensor([[0.9934, 0.0066]]),\n",
       " tensor([[0.9985, 0.0015]]),\n",
       " tensor([[0.9964, 0.0036]]),\n",
       " tensor([[0.9978, 0.0022]]),\n",
       " tensor([[0.0096, 0.9904]]),\n",
       " tensor([[0.0378, 0.9622]]),\n",
       " tensor([[0.9033, 0.0967]]),\n",
       " tensor([[0.9579, 0.0421]]),\n",
       " tensor([[1.0000e+00, 4.2796e-07]]),\n",
       " tensor([[0.7348, 0.2652]]),\n",
       " tensor([[0.7807, 0.2193]]),\n",
       " tensor([[0.9972, 0.0028]]),\n",
       " tensor([[0.0460, 0.9540]]),\n",
       " tensor([[0.4554, 0.5446]]),\n",
       " tensor([[0.9981, 0.0019]]),\n",
       " tensor([[0.9776, 0.0224]]),\n",
       " tensor([[0.9978, 0.0022]]),\n",
       " tensor([[0.9967, 0.0033]]),\n",
       " tensor([[0.9895, 0.0105]]),\n",
       " tensor([[0.6192, 0.3808]]),\n",
       " tensor([[0.1313, 0.8687]]),\n",
       " tensor([[0.8865, 0.1135]]),\n",
       " tensor([[0.0116, 0.9884]]),\n",
       " tensor([[1.0000e+00, 5.2019e-19]]),\n",
       " tensor([[0.9843, 0.0157]]),\n",
       " tensor([[0.0092, 0.9908]]),\n",
       " tensor([[0.9758, 0.0242]]),\n",
       " tensor([[0.8741, 0.1259]]),\n",
       " tensor([[0.0162, 0.9838]]),\n",
       " tensor([[0.9920, 0.0080]]),\n",
       " tensor([[9.9929e-01, 7.0814e-04]]),\n",
       " tensor([[0.0109, 0.9891]]),\n",
       " tensor([[1.0000e+00, 1.2002e-18]]),\n",
       " tensor([[0.2744, 0.7256]]),\n",
       " tensor([[0.0344, 0.9656]]),\n",
       " tensor([[0.9691, 0.0309]]),\n",
       " tensor([[0.9466, 0.0534]]),\n",
       " tensor([[0.7761, 0.2239]]),\n",
       " tensor([[0.0762, 0.9238]]),\n",
       " tensor([[0.1983, 0.8017]]),\n",
       " tensor([[0.9611, 0.0389]]),\n",
       " tensor([[0.0457, 0.9543]]),\n",
       " tensor([[0.0420, 0.9580]]),\n",
       " tensor([[0.0250, 0.9750]]),\n",
       " tensor([[0.9943, 0.0057]]),\n",
       " tensor([[0.0492, 0.9508]]),\n",
       " tensor([[0.9985, 0.0015]]),\n",
       " tensor([[1.0000e+00, 1.5094e-10]]),\n",
       " tensor([[0.0135, 0.9865]]),\n",
       " tensor([[0.9904, 0.0096]]),\n",
       " tensor([[0.9560, 0.0440]]),\n",
       " tensor([[0.0249, 0.9751]]),\n",
       " tensor([[0.9958, 0.0042]]),\n",
       " tensor([[0.6647, 0.3353]]),\n",
       " tensor([[0.0774, 0.9226]]),\n",
       " tensor([[0.0937, 0.9063]]),\n",
       " tensor([[0.9839, 0.0162]]),\n",
       " tensor([[0.0128, 0.9872]]),\n",
       " tensor([[0.0356, 0.9644]]),\n",
       " tensor([[0.3080, 0.6920]]),\n",
       " tensor([[0.8004, 0.1996]]),\n",
       " tensor([[0.0556, 0.9444]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[0.0131, 0.9869]]),\n",
       " tensor([[0.9955, 0.0045]]),\n",
       " tensor([[0.8191, 0.1809]]),\n",
       " tensor([[0.9826, 0.0174]]),\n",
       " tensor([[0.0123, 0.9877]]),\n",
       " tensor([[1.0000e+00, 2.2539e-19]]),\n",
       " tensor([[0.0477, 0.9523]]),\n",
       " tensor([[0.1898, 0.8102]]),\n",
       " tensor([[0.0286, 0.9714]]),\n",
       " tensor([[0.9973, 0.0027]]),\n",
       " tensor([[0.0756, 0.9244]]),\n",
       " tensor([[0.9884, 0.0116]]),\n",
       " tensor([[0.6855, 0.3145]]),\n",
       " tensor([[0.0107, 0.9893]]),\n",
       " tensor([[0.0204, 0.9796]]),\n",
       " tensor([[0.9570, 0.0430]]),\n",
       " tensor([[0.9873, 0.0127]]),\n",
       " tensor([[0.9955, 0.0045]]),\n",
       " tensor([[0.9967, 0.0033]]),\n",
       " tensor([[1.0000e+00, 7.7516e-21]]),\n",
       " tensor([[0.4931, 0.5069]]),\n",
       " tensor([[0.9987, 0.0013]]),\n",
       " tensor([[0.0312, 0.9688]]),\n",
       " tensor([[0.9872, 0.0128]]),\n",
       " tensor([[0.9858, 0.0142]]),\n",
       " tensor([[1.0000e+00, 6.0041e-20]]),\n",
       " tensor([[0.9948, 0.0052]]),\n",
       " tensor([[0.4875, 0.5125]]),\n",
       " tensor([[0.9628, 0.0372]]),\n",
       " tensor([[0.1580, 0.8420]]),\n",
       " tensor([[0.9648, 0.0352]]),\n",
       " tensor([[0.9276, 0.0724]]),\n",
       " tensor([[0.7225, 0.2775]]),\n",
       " tensor([[0.9926, 0.0074]]),\n",
       " tensor([[0.9757, 0.0243]]),\n",
       " tensor([[0.0143, 0.9857]]),\n",
       " tensor([[0.9956, 0.0044]]),\n",
       " tensor([[0.4605, 0.5395]]),\n",
       " tensor([[0.9228, 0.0772]]),\n",
       " tensor([[0.0130, 0.9870]]),\n",
       " tensor([[0.8921, 0.1079]]),\n",
       " tensor([[0.9960, 0.0040]]),\n",
       " tensor([[0.9977, 0.0023]]),\n",
       " tensor([[0.1943, 0.8057]]),\n",
       " tensor([[0.9531, 0.0469]]),\n",
       " tensor([[0.9809, 0.0191]]),\n",
       " tensor([[0.0550, 0.9450]]),\n",
       " tensor([[0.8235, 0.1765]]),\n",
       " tensor([[0.0372, 0.9628]]),\n",
       " tensor([[0.9369, 0.0631]]),\n",
       " tensor([[0.9939, 0.0061]]),\n",
       " tensor([[1.0000e+00, 4.8974e-21]]),\n",
       " tensor([[0.9310, 0.0690]]),\n",
       " tensor([[0.8993, 0.1007]]),\n",
       " tensor([[0.9947, 0.0053]]),\n",
       " tensor([[0.0033, 0.9967]]),\n",
       " tensor([[0.9971, 0.0029]]),\n",
       " tensor([[0.1352, 0.8648]]),\n",
       " tensor([[0.9954, 0.0046]]),\n",
       " tensor([[0.9949, 0.0051]]),\n",
       " tensor([[0.9942, 0.0058]]),\n",
       " tensor([[0.1032, 0.8968]]),\n",
       " tensor([[0.9904, 0.0096]]),\n",
       " tensor([[1.0000e+00, 4.5842e-20]]),\n",
       " tensor([[0.1011, 0.8989]]),\n",
       " tensor([[0.9757, 0.0243]]),\n",
       " tensor([[0.0506, 0.9494]]),\n",
       " tensor([[0.0383, 0.9617]]),\n",
       " tensor([[0.9954, 0.0046]]),\n",
       " tensor([[0.0855, 0.9145]]),\n",
       " tensor([[1.0000e+00, 7.2976e-13]]),\n",
       " tensor([[0.9941, 0.0059]]),\n",
       " tensor([[0.9964, 0.0036]]),\n",
       " tensor([[0.9974, 0.0026]]),\n",
       " tensor([[0.9766, 0.0234]]),\n",
       " tensor([[0.0786, 0.9214]]),\n",
       " tensor([[0.9832, 0.0168]]),\n",
       " tensor([[0.9938, 0.0062]]),\n",
       " tensor([[0.9865, 0.0135]]),\n",
       " tensor([[0.0231, 0.9769]]),\n",
       " tensor([[0.9971, 0.0029]]),\n",
       " tensor([[0.6387, 0.3613]]),\n",
       " tensor([[0.9839, 0.0161]]),\n",
       " tensor([[0.1239, 0.8761]]),\n",
       " tensor([[0.0523, 0.9477]]),\n",
       " tensor([[0.9959, 0.0041]]),\n",
       " tensor([[0.0250, 0.9750]]),\n",
       " tensor([[0.9788, 0.0212]]),\n",
       " tensor([[0.9896, 0.0104]]),\n",
       " tensor([[0.8089, 0.1911]]),\n",
       " tensor([[0.9929, 0.0071]]),\n",
       " tensor([[0.9968, 0.0032]]),\n",
       " tensor([[0.8918, 0.1082]]),\n",
       " tensor([[0.9885, 0.0115]]),\n",
       " tensor([[0.2763, 0.7237]]),\n",
       " tensor([[0.1420, 0.8580]]),\n",
       " tensor([[0.9813, 0.0187]]),\n",
       " tensor([[0.3298, 0.6702]]),\n",
       " tensor([[0.0024, 0.9976]]),\n",
       " tensor([[0.0513, 0.9487]]),\n",
       " tensor([[0.0562, 0.9438]]),\n",
       " tensor([[0.9934, 0.0066]]),\n",
       " tensor([[0.9978, 0.0022]]),\n",
       " tensor([[0.9716, 0.0284]]),\n",
       " tensor([[0.8076, 0.1924]]),\n",
       " tensor([[0.0370, 0.9630]]),\n",
       " tensor([[0.9972, 0.0028]]),\n",
       " tensor([[0.9939, 0.0061]]),\n",
       " tensor([[1.0000e+00, 7.4319e-21]]),\n",
       " tensor([[0.9977, 0.0023]]),\n",
       " tensor([[0.9373, 0.0627]]),\n",
       " tensor([[0.9932, 0.0068]]),\n",
       " tensor([[0.9904, 0.0096]]),\n",
       " tensor([[0.3343, 0.6657]]),\n",
       " tensor([[0.7942, 0.2058]]),\n",
       " tensor([[0.9979, 0.0021]]),\n",
       " tensor([[0.5570, 0.4430]]),\n",
       " tensor([[0.0095, 0.9905]]),\n",
       " tensor([[1.0000e+00, 5.4010e-17]]),\n",
       " tensor([[0.7957, 0.2043]]),\n",
       " tensor([[0.9870, 0.0130]]),\n",
       " tensor([[0.9777, 0.0223]]),\n",
       " tensor([[0.9881, 0.0119]]),\n",
       " tensor([[0.9881, 0.0119]]),\n",
       " tensor([[0.1498, 0.8502]]),\n",
       " tensor([[0.0147, 0.9853]]),\n",
       " tensor([[0.9716, 0.0284]]),\n",
       " tensor([[0.0132, 0.9868]]),\n",
       " tensor([[0.8364, 0.1636]]),\n",
       " tensor([[0.7118, 0.2882]]),\n",
       " tensor([[0.8424, 0.1576]]),\n",
       " tensor([[0.5749, 0.4251]]),\n",
       " tensor([[0.1754, 0.8246]]),\n",
       " tensor([[0.9718, 0.0282]]),\n",
       " tensor([[0.9891, 0.0109]]),\n",
       " tensor([[0.0019, 0.9981]]),\n",
       " tensor([[0.9914, 0.0086]]),\n",
       " tensor([[0.9967, 0.0033]]),\n",
       " tensor([[0.9808, 0.0192]]),\n",
       " tensor([[0.9888, 0.0112]]),\n",
       " tensor([[0.0149, 0.9851]]),\n",
       " tensor([[0.4195, 0.5805]]),\n",
       " tensor([[0.8334, 0.1666]]),\n",
       " tensor([[0.9956, 0.0044]]),\n",
       " tensor([[0.9776, 0.0224]]),\n",
       " tensor([[0.6816, 0.3184]]),\n",
       " tensor([[0.0072, 0.9928]]),\n",
       " tensor([[0.9987, 0.0013]]),\n",
       " tensor([[0.9480, 0.0520]]),\n",
       " tensor([[1.0000e+00, 1.7596e-06]]),\n",
       " tensor([[0.9341, 0.0659]]),\n",
       " tensor([[0.9633, 0.0367]]),\n",
       " tensor([[0.0192, 0.9808]]),\n",
       " tensor([[0.9883, 0.0117]]),\n",
       " tensor([[0.3202, 0.6798]]),\n",
       " tensor([[0.9883, 0.0117]]),\n",
       " tensor([[0.9442, 0.0558]]),\n",
       " tensor([[0.0480, 0.9520]]),\n",
       " tensor([[0.0280, 0.9720]]),\n",
       " tensor([[0.9440, 0.0560]]),\n",
       " tensor([[0.5914, 0.4086]]),\n",
       " tensor([[0.9972, 0.0028]]),\n",
       " tensor([[0.0036, 0.9964]]),\n",
       " tensor([[0.9242, 0.0758]]),\n",
       " tensor([[0.9898, 0.0102]]),\n",
       " tensor([[0.0937, 0.9063]]),\n",
       " tensor([[0.2653, 0.7347]]),\n",
       " tensor([[0.0779, 0.9221]]),\n",
       " tensor([[0.9342, 0.0658]]),\n",
       " tensor([[0.9887, 0.0113]]),\n",
       " tensor([[0.8573, 0.1427]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[0.1665, 0.8335]]),\n",
       " tensor([[0.1576, 0.8424]]),\n",
       " tensor([[0.2321, 0.7679]]),\n",
       " tensor([[0.6222, 0.3778]]),\n",
       " tensor([[0.9805, 0.0195]]),\n",
       " tensor([[0.8480, 0.1520]]),\n",
       " tensor([[0.2307, 0.7693]]),\n",
       " tensor([[0.0320, 0.9680]]),\n",
       " tensor([[0.8452, 0.1548]]),\n",
       " tensor([[0.1450, 0.8550]]),\n",
       " tensor([[0.9529, 0.0471]]),\n",
       " tensor([[0.0756, 0.9244]]),\n",
       " tensor([[0.0036, 0.9964]]),\n",
       " tensor([[0.9810, 0.0190]]),\n",
       " tensor([[0.8935, 0.1065]]),\n",
       " tensor([[1.0000e+00, 1.2401e-20]]),\n",
       " tensor([[0.2292, 0.7708]]),\n",
       " tensor([[0.0677, 0.9323]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[0.9855, 0.0145]]),\n",
       " tensor([[0.9841, 0.0159]]),\n",
       " tensor([[0.9737, 0.0263]]),\n",
       " tensor([[0.9948, 0.0052]]),\n",
       " tensor([[0.9742, 0.0258]]),\n",
       " tensor([[0.7910, 0.2090]]),\n",
       " tensor([[0.9940, 0.0060]]),\n",
       " tensor([[0.9781, 0.0219]]),\n",
       " tensor([[0.9925, 0.0075]]),\n",
       " tensor([[0.8405, 0.1595]]),\n",
       " tensor([[0.9628, 0.0372]]),\n",
       " tensor([[0.2245, 0.7755]]),\n",
       " tensor([[0.0140, 0.9860]]),\n",
       " tensor([[0.9796, 0.0204]]),\n",
       " tensor([[0.9982, 0.0018]]),\n",
       " tensor([[0.9973, 0.0027]]),\n",
       " tensor([[0.5208, 0.4792]]),\n",
       " tensor([[0.0269, 0.9731]]),\n",
       " tensor([[0.8869, 0.1131]]),\n",
       " tensor([[0.0674, 0.9326]]),\n",
       " tensor([[0.9801, 0.0199]]),\n",
       " tensor([[0.9986, 0.0014]]),\n",
       " tensor([[0.0185, 0.9815]]),\n",
       " tensor([[0.9975, 0.0025]]),\n",
       " tensor([[0.6364, 0.3636]]),\n",
       " tensor([[0.9911, 0.0089]]),\n",
       " tensor([[0.0898, 0.9102]]),\n",
       " tensor([[0.9960, 0.0040]]),\n",
       " tensor([[0.0075, 0.9925]]),\n",
       " tensor([[0.9873, 0.0127]]),\n",
       " tensor([[0.0113, 0.9887]]),\n",
       " tensor([[0.0542, 0.9458]]),\n",
       " tensor([[0.9876, 0.0124]]),\n",
       " tensor([[0.9706, 0.0294]]),\n",
       " tensor([[0.9948, 0.0052]]),\n",
       " tensor([[0.8479, 0.1521]]),\n",
       " tensor([[0.0363, 0.9637]]),\n",
       " tensor([[0.9935, 0.0065]]),\n",
       " tensor([[0.9974, 0.0026]]),\n",
       " tensor([[0.0098, 0.9902]]),\n",
       " tensor([[0.9861, 0.0139]]),\n",
       " tensor([[0.9869, 0.0131]]),\n",
       " tensor([[0.9575, 0.0425]]),\n",
       " tensor([[0.0461, 0.9539]]),\n",
       " tensor([[0.9652, 0.0348]]),\n",
       " tensor([[0.9369, 0.0631]]),\n",
       " tensor([[0.9833, 0.0167]]),\n",
       " tensor([[0.9141, 0.0859]]),\n",
       " tensor([[0.9908, 0.0092]]),\n",
       " tensor([[0.4052, 0.5948]]),\n",
       " tensor([[0.0341, 0.9659]]),\n",
       " tensor([[0.0929, 0.9071]]),\n",
       " tensor([[0.0468, 0.9532]]),\n",
       " tensor([[0.8973, 0.1027]]),\n",
       " tensor([[0.7894, 0.2106]]),\n",
       " tensor([[0.5741, 0.4259]]),\n",
       " tensor([[0.9520, 0.0480]]),\n",
       " tensor([[0.9987, 0.0013]]),\n",
       " tensor([[0.6623, 0.3377]]),\n",
       " tensor([[0.9893, 0.0107]]),\n",
       " tensor([[0.0147, 0.9853]]),\n",
       " tensor([[0.9864, 0.0136]]),\n",
       " tensor([[0.1223, 0.8777]]),\n",
       " tensor([[0.9913, 0.0087]]),\n",
       " tensor([[0.1102, 0.8898]]),\n",
       " tensor([[0.9098, 0.0902]]),\n",
       " tensor([[0.9607, 0.0393]]),\n",
       " tensor([[0.0285, 0.9715]]),\n",
       " tensor([[0.0186, 0.9814]]),\n",
       " tensor([[0.1185, 0.8815]]),\n",
       " tensor([[0.8915, 0.1085]]),\n",
       " tensor([[0.0020, 0.9980]]),\n",
       " tensor([[0.9315, 0.0685]]),\n",
       " tensor([[0.8862, 0.1138]]),\n",
       " tensor([[0.5737, 0.4263]]),\n",
       " tensor([[0.9953, 0.0047]]),\n",
       " tensor([[0.1386, 0.8614]]),\n",
       " tensor([[0.0082, 0.9918]]),\n",
       " tensor([[9.9923e-01, 7.6677e-04]]),\n",
       " tensor([[0.9954, 0.0046]]),\n",
       " tensor([[0.9279, 0.0721]]),\n",
       " tensor([[0.8873, 0.1127]]),\n",
       " tensor([[0.0099, 0.9901]]),\n",
       " tensor([[0.8736, 0.1264]]),\n",
       " tensor([[0.8658, 0.1342]]),\n",
       " tensor([[0.9931, 0.0069]]),\n",
       " tensor([[0.9989, 0.0011]]),\n",
       " tensor([[0.8037, 0.1963]]),\n",
       " tensor([[0.0655, 0.9345]]),\n",
       " tensor([[0.9942, 0.0058]]),\n",
       " tensor([[0.7885, 0.2115]]),\n",
       " tensor([[0.7949, 0.2051]]),\n",
       " tensor([[0.9949, 0.0051]]),\n",
       " tensor([[0.9736, 0.0264]]),\n",
       " tensor([[0.1082, 0.8918]]),\n",
       " tensor([[0.0823, 0.9177]]),\n",
       " tensor([[0.1148, 0.8852]]),\n",
       " tensor([[0.9973, 0.0027]]),\n",
       " tensor([[0.2002, 0.7998]]),\n",
       " tensor([[0.9936, 0.0064]]),\n",
       " tensor([[0.0588, 0.9412]]),\n",
       " tensor([[0.0352, 0.9648]]),\n",
       " tensor([[0.9907, 0.0093]]),\n",
       " tensor([[0.7002, 0.2998]]),\n",
       " tensor([[0.9984, 0.0016]]),\n",
       " tensor([[0.9969, 0.0031]]),\n",
       " tensor([[0.9551, 0.0449]]),\n",
       " tensor([[0.0747, 0.9253]]),\n",
       " tensor([[0.9966, 0.0034]]),\n",
       " tensor([[0.2761, 0.7239]]),\n",
       " tensor([[0.9930, 0.0070]]),\n",
       " tensor([[0.7695, 0.2305]]),\n",
       " tensor([[0.9250, 0.0750]]),\n",
       " tensor([[0.0276, 0.9724]]),\n",
       " tensor([[0.1423, 0.8577]]),\n",
       " tensor([[0.1227, 0.8773]]),\n",
       " tensor([[1.0000e+00, 1.9003e-07]]),\n",
       " tensor([[0.9797, 0.0203]]),\n",
       " tensor([[0.9918, 0.0082]]),\n",
       " tensor([[0.7236, 0.2764]]),\n",
       " tensor([[0.7366, 0.2634]]),\n",
       " tensor([[0.8364, 0.1636]]),\n",
       " tensor([[1.0000e+00, 2.3751e-13]]),\n",
       " tensor([[0.9959, 0.0041]]),\n",
       " tensor([[0.9935, 0.0065]]),\n",
       " tensor([[0.0299, 0.9701]]),\n",
       " tensor([[0.0258, 0.9742]]),\n",
       " tensor([[0.9914, 0.0086]]),\n",
       " tensor([[0.0338, 0.9662]]),\n",
       " tensor([[0.9369, 0.0631]]),\n",
       " tensor([[0.9982, 0.0018]]),\n",
       " tensor([[0.6936, 0.3064]]),\n",
       " tensor([[0.9942, 0.0058]]),\n",
       " tensor([[0.9923, 0.0077]]),\n",
       " tensor([[0.0124, 0.9876]]),\n",
       " tensor([[0.0806, 0.9194]]),\n",
       " tensor([[0.2493, 0.7507]]),\n",
       " tensor([[0.0112, 0.9888]]),\n",
       " tensor([[0.2266, 0.7734]]),\n",
       " tensor([[0.9300, 0.0700]]),\n",
       " tensor([[0.0502, 0.9498]]),\n",
       " tensor([[0.1180, 0.8820]]),\n",
       " tensor([[0.7867, 0.2133]]),\n",
       " tensor([[0.2771, 0.7229]]),\n",
       " tensor([[0.9969, 0.0031]]),\n",
       " tensor([[0.2839, 0.7161]]),\n",
       " tensor([[0.2552, 0.7448]]),\n",
       " tensor([[0.0766, 0.9234]]),\n",
       " tensor([[0.9439, 0.0561]]),\n",
       " tensor([[0.9204, 0.0796]]),\n",
       " tensor([[0.9809, 0.0191]]),\n",
       " tensor([[0.9921, 0.0079]]),\n",
       " tensor([[0.0100, 0.9900]]),\n",
       " tensor([[0.9951, 0.0049]]),\n",
       " tensor([[0.9396, 0.0604]]),\n",
       " tensor([[0.7956, 0.2044]]),\n",
       " tensor([[0.7637, 0.2363]]),\n",
       " tensor([[0.7726, 0.2274]]),\n",
       " tensor([[0.0509, 0.9491]]),\n",
       " tensor([[1.0000e+00, 6.3585e-20]]),\n",
       " tensor([[0.0020, 0.9980]]),\n",
       " tensor([[0.9779, 0.0221]]),\n",
       " tensor([[0.9456, 0.0544]]),\n",
       " tensor([[0.6445, 0.3555]]),\n",
       " tensor([[0.9844, 0.0156]]),\n",
       " tensor([[0.9347, 0.0653]]),\n",
       " tensor([[1.0000e+00, 3.1983e-09]]),\n",
       " tensor([[0.4694, 0.5306]]),\n",
       " tensor([[0.7270, 0.2730]]),\n",
       " tensor([[0.0439, 0.9561]]),\n",
       " tensor([[0.0739, 0.9261]]),\n",
       " tensor([[0.9916, 0.0084]]),\n",
       " tensor([[0.9892, 0.0108]]),\n",
       " tensor([[0.7560, 0.2440]]),\n",
       " tensor([[0.9407, 0.0593]]),\n",
       " tensor([[0.9946, 0.0054]]),\n",
       " tensor([[0.9307, 0.0693]]),\n",
       " tensor([[0.0500, 0.9500]]),\n",
       " tensor([[0.9799, 0.0201]]),\n",
       " tensor([[0.9866, 0.0134]]),\n",
       " tensor([[0.3194, 0.6806]]),\n",
       " tensor([[0.9928, 0.0072]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[0.0728, 0.9272]]),\n",
       " tensor([[0.9214, 0.0786]]),\n",
       " tensor([[0.9470, 0.0530]]),\n",
       " tensor([[0.9930, 0.0070]]),\n",
       " tensor([[0.7346, 0.2654]]),\n",
       " tensor([[0.0074, 0.9926]]),\n",
       " tensor([[0.9975, 0.0025]]),\n",
       " tensor([[0.9054, 0.0946]]),\n",
       " tensor([[0.3945, 0.6055]]),\n",
       " tensor([[0.5816, 0.4184]]),\n",
       " tensor([[0.0816, 0.9184]]),\n",
       " tensor([[0.0285, 0.9715]]),\n",
       " tensor([[0.0281, 0.9719]]),\n",
       " tensor([[0.7388, 0.2612]]),\n",
       " tensor([[0.9835, 0.0165]]),\n",
       " tensor([[1.0000e+00, 7.5062e-07]]),\n",
       " tensor([[0.9711, 0.0289]]),\n",
       " tensor([[1.0000e+00, 3.4766e-13]]),\n",
       " tensor([[0.9961, 0.0039]]),\n",
       " tensor([[0.0904, 0.9096]]),\n",
       " tensor([[0.7946, 0.2054]]),\n",
       " tensor([[0.8135, 0.1865]]),\n",
       " tensor([[0.9926, 0.0074]]),\n",
       " tensor([[0.9713, 0.0287]]),\n",
       " tensor([[0.0026, 0.9974]]),\n",
       " tensor([[0.9762, 0.0238]]),\n",
       " tensor([[0.9864, 0.0136]]),\n",
       " tensor([[0.7487, 0.2513]]),\n",
       " tensor([[0.9986, 0.0014]]),\n",
       " tensor([[0.8987, 0.1013]]),\n",
       " tensor([[0.9973, 0.0027]]),\n",
       " tensor([[0.8847, 0.1153]]),\n",
       " tensor([[0.9813, 0.0187]]),\n",
       " tensor([[0.9902, 0.0098]]),\n",
       " tensor([[0.8774, 0.1226]]),\n",
       " tensor([[0.0109, 0.9891]]),\n",
       " tensor([[0.9808, 0.0192]]),\n",
       " tensor([[0.0246, 0.9754]]),\n",
       " tensor([[0.0995, 0.9005]]),\n",
       " tensor([[0.9894, 0.0106]]),\n",
       " tensor([[0.9978, 0.0022]]),\n",
       " tensor([[0.0345, 0.9655]]),\n",
       " tensor([[0.0158, 0.9842]]),\n",
       " tensor([[0.0174, 0.9826]]),\n",
       " tensor([[0.0956, 0.9044]]),\n",
       " tensor([[1.0000e+00, 6.7067e-08]]),\n",
       " tensor([[0.4169, 0.5831]]),\n",
       " tensor([[0.5727, 0.4273]]),\n",
       " tensor([[0.9867, 0.0133]]),\n",
       " tensor([[0.9990, 0.0010]]),\n",
       " tensor([[0.8762, 0.1238]]),\n",
       " tensor([[0.9953, 0.0047]]),\n",
       " tensor([[0.9259, 0.0741]]),\n",
       " tensor([[0.9118, 0.0882]]),\n",
       " tensor([[0.9958, 0.0042]]),\n",
       " tensor([[0.0353, 0.9647]]),\n",
       " tensor([[0.9944, 0.0056]]),\n",
       " tensor([[0.9952, 0.0048]]),\n",
       " tensor([[0.9821, 0.0179]]),\n",
       " tensor([[0.9371, 0.0629]]),\n",
       " tensor([[0.0122, 0.9878]]),\n",
       " tensor([[0.9562, 0.0438]]),\n",
       " tensor([[0.9934, 0.0066]]),\n",
       " tensor([[0.8819, 0.1181]]),\n",
       " tensor([[0.9904, 0.0096]]),\n",
       " tensor([[9.9925e-01, 7.5398e-04]]),\n",
       " tensor([[0.0207, 0.9793]]),\n",
       " tensor([[0.9960, 0.0040]]),\n",
       " tensor([[0.1281, 0.8719]]),\n",
       " tensor([[0.1961, 0.8039]]),\n",
       " tensor([[0.0286, 0.9714]]),\n",
       " tensor([[0.9560, 0.0440]]),\n",
       " tensor([[0.1112, 0.8888]]),\n",
       " tensor([[0.9892, 0.0108]]),\n",
       " tensor([[0.1878, 0.8122]]),\n",
       " tensor([[0.1746, 0.8254]]),\n",
       " tensor([[0.3892, 0.6108]]),\n",
       " tensor([[0.0415, 0.9585]]),\n",
       " tensor([[1.0000e+00, 8.8912e-22]]),\n",
       " tensor([[0.9207, 0.0793]]),\n",
       " tensor([[0.9843, 0.0157]]),\n",
       " tensor([[0.9919, 0.0081]]),\n",
       " tensor([[0.9883, 0.0117]]),\n",
       " tensor([[0.9921, 0.0079]]),\n",
       " tensor([[0.7509, 0.2491]]),\n",
       " tensor([[0.5647, 0.4353]]),\n",
       " tensor([[0.6242, 0.3758]]),\n",
       " tensor([[0.9791, 0.0209]]),\n",
       " tensor([[0.9833, 0.0167]]),\n",
       " tensor([[0.0095, 0.9905]]),\n",
       " tensor([[0.9908, 0.0092]]),\n",
       " tensor([[0.9950, 0.0050]]),\n",
       " tensor([[0.1891, 0.8109]]),\n",
       " tensor([[0.9925, 0.0075]]),\n",
       " tensor([[0.9827, 0.0173]]),\n",
       " tensor([[0.0301, 0.9699]]),\n",
       " tensor([[0.0496, 0.9504]]),\n",
       " tensor([[0.0433, 0.9567]]),\n",
       " tensor([[0.0763, 0.9237]]),\n",
       " tensor([[0.9853, 0.0147]]),\n",
       " tensor([[0.9956, 0.0044]]),\n",
       " tensor([[0.3365, 0.6635]]),\n",
       " tensor([[0.9933, 0.0067]]),\n",
       " tensor([[0.0024, 0.9976]]),\n",
       " tensor([[0.9374, 0.0626]]),\n",
       " tensor([[0.9635, 0.0365]]),\n",
       " tensor([[0.2274, 0.7726]]),\n",
       " tensor([[0.1136, 0.8864]]),\n",
       " tensor([[0.9979, 0.0021]]),\n",
       " tensor([[0.9971, 0.0029]]),\n",
       " tensor([[0.9875, 0.0125]]),\n",
       " tensor([[0.0533, 0.9467]]),\n",
       " tensor([[0.6962, 0.3038]]),\n",
       " tensor([[0.9492, 0.0508]]),\n",
       " tensor([[0.9833, 0.0167]]),\n",
       " tensor([[0.8536, 0.1464]]),\n",
       " tensor([[0.9730, 0.0270]]),\n",
       " tensor([[0.1215, 0.8785]]),\n",
       " tensor([[0.0037, 0.9963]]),\n",
       " tensor([[0.0888, 0.9112]]),\n",
       " tensor([[0.9790, 0.0210]]),\n",
       " tensor([[0.9962, 0.0038]]),\n",
       " tensor([[0.1722, 0.8278]]),\n",
       " tensor([[0.0493, 0.9507]]),\n",
       " tensor([[0.8173, 0.1827]]),\n",
       " tensor([[0.9933, 0.0067]]),\n",
       " tensor([[0.9939, 0.0061]]),\n",
       " tensor([[0.9829, 0.0171]]),\n",
       " tensor([[0.9976, 0.0024]]),\n",
       " tensor([[0.7224, 0.2776]]),\n",
       " tensor([[0.9935, 0.0065]]),\n",
       " tensor([[0.9280, 0.0720]]),\n",
       " tensor([[9.9920e-01, 7.9797e-04]]),\n",
       " tensor([[0.0741, 0.9259]]),\n",
       " tensor([[0.4848, 0.5152]]),\n",
       " tensor([[0.9921, 0.0079]]),\n",
       " tensor([[0.3954, 0.6046]]),\n",
       " tensor([[0.0329, 0.9671]]),\n",
       " tensor([[0.0023, 0.9977]]),\n",
       " tensor([[0.9096, 0.0904]]),\n",
       " tensor([[0.0252, 0.9748]]),\n",
       " tensor([[0.1202, 0.8798]]),\n",
       " tensor([[0.0163, 0.9837]]),\n",
       " tensor([[0.1559, 0.8441]]),\n",
       " tensor([[0.9135, 0.0865]]),\n",
       " tensor([[0.9851, 0.0149]]),\n",
       " tensor([[0.0303, 0.9697]]),\n",
       " tensor([[0.9950, 0.0050]]),\n",
       " tensor([[1.0000e+00, 5.3785e-11]]),\n",
       " tensor([[0.9127, 0.0873]]),\n",
       " tensor([[0.9307, 0.0693]]),\n",
       " tensor([[0.0876, 0.9124]]),\n",
       " tensor([[0.0466, 0.9534]]),\n",
       " tensor([[0.5279, 0.4721]]),\n",
       " tensor([[0.7800, 0.2200]]),\n",
       " tensor([[0.9885, 0.0115]]),\n",
       " tensor([[0.9663, 0.0337]]),\n",
       " tensor([[0.0953, 0.9047]]),\n",
       " tensor([[0.9688, 0.0312]]),\n",
       " tensor([[0.1500, 0.8500]]),\n",
       " tensor([[0.9941, 0.0059]]),\n",
       " tensor([[0.0289, 0.9711]]),\n",
       " tensor([[0.7506, 0.2494]]),\n",
       " tensor([[0.9864, 0.0136]]),\n",
       " tensor([[0.9986, 0.0014]]),\n",
       " tensor([[0.9839, 0.0161]]),\n",
       " tensor([[0.0529, 0.9471]]),\n",
       " tensor([[0.9938, 0.0062]]),\n",
       " tensor([[1.0000e+00, 1.6056e-07]]),\n",
       " tensor([[0.9969, 0.0031]]),\n",
       " tensor([[0.9977, 0.0023]]),\n",
       " tensor([[0.0251, 0.9749]]),\n",
       " tensor([[1.0000e+00, 1.9579e-15]]),\n",
       " tensor([[0.3045, 0.6955]]),\n",
       " tensor([[0.0450, 0.9550]]),\n",
       " tensor([[0.9963, 0.0037]]),\n",
       " tensor([[0.9956, 0.0044]]),\n",
       " tensor([[0.6294, 0.3706]]),\n",
       " tensor([[0.9522, 0.0478]]),\n",
       " tensor([[0.7057, 0.2943]]),\n",
       " tensor([[0.0424, 0.9576]]),\n",
       " tensor([[0.0296, 0.9704]]),\n",
       " tensor([[0.0064, 0.9936]]),\n",
       " tensor([[0.0608, 0.9392]]),\n",
       " tensor([[0.7554, 0.2446]]),\n",
       " tensor([[0.6234, 0.3766]]),\n",
       " tensor([[0.9956, 0.0044]]),\n",
       " tensor([[0.9960, 0.0040]]),\n",
       " tensor([[0.8215, 0.1785]]),\n",
       " tensor([[0.9955, 0.0045]]),\n",
       " tensor([[0.9706, 0.0294]]),\n",
       " tensor([[0.9970, 0.0030]]),\n",
       " tensor([[0.7977, 0.2023]]),\n",
       " tensor([[0.9985, 0.0015]]),\n",
       " tensor([[0.8865, 0.1135]]),\n",
       " tensor([[0.6512, 0.3488]]),\n",
       " tensor([[0.9902, 0.0098]]),\n",
       " tensor([[0.9947, 0.0053]]),\n",
       " tensor([[0.9065, 0.0935]]),\n",
       " tensor([[0.9805, 0.0195]]),\n",
       " tensor([[0.9325, 0.0675]]),\n",
       " tensor([[0.8240, 0.1760]]),\n",
       " tensor([[0.9862, 0.0138]]),\n",
       " tensor([[0.9983, 0.0017]]),\n",
       " tensor([[0.8191, 0.1809]]),\n",
       " tensor([[0.0042, 0.9958]]),\n",
       " tensor([[0.9974, 0.0026]]),\n",
       " tensor([[0.7630, 0.2370]]),\n",
       " tensor([[0.6901, 0.3099]]),\n",
       " tensor([[0.9989, 0.0011]]),\n",
       " tensor([[0.3498, 0.6502]]),\n",
       " tensor([[0.0288, 0.9712]]),\n",
       " tensor([[0.2308, 0.7692]]),\n",
       " tensor([[0.9849, 0.0151]]),\n",
       " tensor([[0.0179, 0.9821]]),\n",
       " tensor([[1.0000e+00, 3.8532e-15]]),\n",
       " tensor([[0.9989, 0.0011]]),\n",
       " tensor([[9.9916e-01, 8.4438e-04]]),\n",
       " tensor([[0.4500, 0.5500]]),\n",
       " tensor([[0.0354, 0.9646]]),\n",
       " tensor([[0.0351, 0.9649]]),\n",
       " tensor([[0.9361, 0.0639]]),\n",
       " tensor([[0.9385, 0.0615]]),\n",
       " tensor([[0.9979, 0.0021]]),\n",
       " tensor([[0.0891, 0.9109]]),\n",
       " tensor([[0.0275, 0.9725]]),\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88a52b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e34e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision1 = precision_score(y_test, preds)\n",
    "recall1 = recall_score(y_test, preds)\n",
    "F1_score = f1_score(y_test, preds)\n",
    "confusion_mat_test = confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5150d3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649386084583902"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5087f360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869684499314129"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d333d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8673050615595076"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6218c60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1262,   99],\n",
       "       [  95,  634]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d072eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5999697, 0.4000303]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range (len(probs)):\n",
    "    result.append(probs[i].numpy())\n",
    "\n",
    "result[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8061cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5999697"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61c4a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below code finds the probability for the positive class\n",
    "resultprobs =[]\n",
    "for i in range(len(result)):\n",
    "    resultprobs.append(result[i][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6aec9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc= roc_auc_score(y_test, resultprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4794e201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664875641145813"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4757276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d78672fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc_curve(fper, tper):  \n",
    "    plt.plot(fper, tper, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "fper, tper, thresholds = roc_curve(y_test, resultprobs) \n",
    "plot_roc_curve(fper, tper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d983a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb12b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c4205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
